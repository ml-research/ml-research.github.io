<!DOCTYPE html>
<!-- saved from url=(0056)./kersting/kersting.html -->
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width">
    <meta name="description" content="">
    <meta name="author" content="">

<title>Probabilistic Graphical models </title>


<link href="./../../css/bootstrap.min.css" rel="stylesheet" media="screen">
<link href="./../../css/jquery.dataTables.min.css" rel="stylesheet" media="screen">
<link href="./../../css/dataTables.bootstrap4.min.css" rel="stylesheet" media="screen">

<link href="./../../css/bootstrap-social.css" rel="stylesheet" media="screen">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<link href="./../../css/style.css" rel="stylesheet">

<script src="./../../build/jquery.min.js"></script>




    <script type='text/javascript'>//<![CDATA[
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {

      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();

        // Store hash
        var hash = this.hash;

        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){

          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>

  <script src="./../../build/jquery.min.js"></script>
  <!--    <script>
      $(function(){
        $("#includedContent").load("myBib.bib");
      });
    </script>-->




</head>



<body data-spy="scroll" data-target=".navbar" data-offset="65">
 <header>
       <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark">

         <a class="navbar-brand" href="#">PGM</a>

         <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarCollapse">
           <span class="navbar-toggler-icon"></span>
         </button>

         <div class="collapse navbar-collapse" id="navbarCollapse">

           <ul class="navbar-nav mr-auto">
             <li class="nav-item">
               <a class="nav-link" href="#goal">Goal</a>
             </li>
             <li class="nav-item">
               <a class="nav-link" href="#material">Material</a>
             </li>
             <li class="nav-item ">
               <a class="nav-link" href="#logistics">Exercises</a>
             </li>
             <li class="nav-item ">
               <a class="nav-link" href="#logistics">Further Material</a>
             </li>

             <li class="nav-item">
               <a class="nav-link" href="https://ml-research.github.io/">AIML@TUDA</a>
             </li>

             <li class="nav-item">
               <a class="nav-link" href="#legal">Legal Info</a>
             </li>
           </ul>

         </div>
       </nav>
 </header>


<main role="main">


<div class="container" id="banner">  <br><br><br>
    <div class="row">
      <div class="col-md-8">

      <img class="img-fluid" src="./images/pgm.png" style="float: left; margin: 0px 0px 10px 10px;">
    </div>
   <div class="clearfix"></div>
</div>
</div>




<div class="container" id="goal">


<div class="row">

  <div class="col-md-9">
        <div id="htname">Probabilistic Graphcial Models (PGM)</div>

      </div>
      </div>




      <br> <b> Moodle:</b> Most communication for this class will take place on Moodle. Please sign up <a href="https://moodle.informatik.tu-darmstadt.de/course/view.php?id=1160"> here </a>.
      <br> <b> Lecture:</b> Monday, 11:40 - 13:20 o'clock, ZOOM
      <br> <b> Exercises:</b> Friday, 11:40 - 13:20 o'clock, ZOOM
      <br> <b> Language:</b> English

<br><br><b> Lectures and exercises take place via Zoom. Please visit the Moodle page to find the link.</b>
<br><br>

<p class="text-justify"><b>Motivation</b>
  Probabilistic graphical models are a powerful framework for representing complex domains using probability distributions,
  with numerous applications in machine learning, computer vision, natural language processing and computational biology.
  Graphical models bring together graph theory and probability theory, and provide a flexible framework for modeling large
  collections of random variables with complex interactions. This course will provide a comprehensive survey of the topic,
  introducing the key formalisms and main techniques used to construct them, make predictions, and support decision-making
  under uncertainty.

The aim of this course is to get in touch with and develop the knowledge and skills necessary to design, implement and apply these models to solve real problems.
The course will cover Bayesian networks (and their temporal extensions),  exact and approximate inference methods, estimation of the parameters and the structure of graphical models.

</p>


</div>

<br>



<hr class="soft">

<div class="container" id="Lecture">

<h3>Lectures</h3>


<p> This course consists of online lectures. We may also provide additional videos and other materials, which
  we recommend to check out, even before the lecture. Please prepare a list of 5 questions
   as extra homework for the videos, since we (all of you) may also try to answer your questions in class.

We may also present our own work.
We may even ask you to read papers, let's see.
Aside from the “5-questions” homework, there are also written
assignments involving both theory and programming. Handing in those assignments regularly will earn
you a bonus for the final exam.</p>

<p> Here are the materials. </p>
<p><TABLE BORDER="0" width="100%" style="border-bottom: 1px solid black">
  <colgroup>
    <col span="1" style="width: 11%;">
    <col span="1" style="width: 10%;">
    <col span="1" style="width: 24%;">
    <col span="1" style="width: 6%;">
    <col span="1" style="width: 13%;">
    <col span="1" style="width: 36%;">
</colgroup>
    <tr style="background-color:#F5F5F5">
    <th>#</th>
    <th>Date</th>
    <th>Description</th>
    <th>Slides</th>
    <th>Recordings<br> Winter 20/21<br> (TU-ID requires)</th>
    <th>Additional Videos</th>


  </tr>
<!--    <TR>
        <div class="t2what" style="background-color:#F5F5F5">Seminar on Machine Learning for Computer Games. <span
                class="t2where">winter 2008</span></div>
    </TR>-->
    <TR>
        <td style = "text-align:center">  1  </td>
        <td> OCt. 18, 2021 </td>
        <td> Course Introduction, Probability Theory</td>
        <td> <a href="./slides/01_tud_PGM01_WiSe202122_intro.pdf" target="_blank">.pdf</a></td>
        <td> <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week1.mp4" target="_blank">.mp4</a></td>

        <td>  <a href="https://www.youtube.com/watch?v=MhMSW3IvbsE&list=PLzERW_Obpmv-_TkPEmCyzaJUGHtl7S01i&index=2"target="_blank">Intro, Koller, Stanford</a><br>
           <a href="https://www.youtube.com/watch?v=ju1Grt2hdko&list=PLL0GjJzXhAWTRiW_ynFswMaiLSa0hjCZ3" target="_blank">Overview PGMs, Bishop, MSR</a><br>
           <a href="https://www.youtube.com/watch?v=BosZK5E_q70" target="_blank"> Overview PGMs, Hennig, Tübingen</a>


        </td>
      </tr>


      <tr style="background-color:#F5F5F5">

        <td  style = "text-align:center"> 2  </td>
        <td> Oct. 25/Nov. 1, 2021 </td>
        <td> Naive Bayes, Independency, Factorization, Local Markov Assumption, ... </td>
        <td> <a href="./slides/02_tud_PGM02_WiSe202122_BN1.pdf" target="_blank">.pdf</a></td>
        <td> <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week2.mp4" target="_blank">.mp4</a><br>
             <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week3.mp4" target="_blank">.mp4</a></td>

        <td> <a href="https://www.youtube.com/watch?v=M59h7CFUwPU"target="_blank">Naive Bayes, Littman/Isbell/Kohle, Gorgia Tech </a><br>
             <a href="https://www.youtube.com/watch?v=cM1BqBv11U8" target="_blank">Chain Rule, Bayes' Rule, Partition, mathematicalmonk</a><br>
             <a href="https://www.youtube.com/watch?v=N0xxCZP0KIc&list=PLzERW_Obpmv-_TkPEmCyzaJUGHtl7S01i&index=3" target="_blank">Joint Distribution, Koller, Stanford</a><br>
             <a href="https://www.youtube.com/watch?v=6xBU74VWEuE&list=PLzERW_Obpmv-_TkPEmCyzaJUGHtl7S01i&index=8" target="_blank">Naive Bayes, Koller, Stanford</a><br>

        </td>



    </TR>

    <tr>

      <td style = "text-align:center"> 3&4  </td>
      <td> Nov. 1/8, 2021 </td>
      <td> d-separation, context-specific independence, variable elimination... </td>
      <td> <a href="./slides/03_tud_PGM03_WiSe202122_BN2.pdf" target="_blank">.pdf</a></td>
      <td> <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week3.mp4" target="_blank">.mp4</a><br>
           <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week4.mp4" target="_blank">.mp4</a></td>

      <td> <a href="https://www.youtube.com/watch?v=yDs_q6jKHb0"target="_blank">d-separation, Abeel, Berkeley </a><br>
           <a href="https://www.youtube.com/watch?v=_haafsCKsmY"target="_blank">Variable elimination, Abeel, Berkeley </a><br>
           <a href="https://www.youtube.com/watch?v=BLbvW6FVniU&list=PLzERW_Obpmv-_TkPEmCyzaJUGHtl7S01i&index=6" target="_blank">Reasoning patterns, Koller, Stanford</a><br>
           <a href="https://www.youtube.com/watch?v=JSrNWurmyLU&list=PLzERW_Obpmv-_TkPEmCyzaJUGHtl7S01i&index=7" target="_blank">Flow of probabilistic influence, Koller, Stanford</a><br>
           <a href="https://www.youtube.com/watch?v=Xhdpk9HZQuo"target="_blank">Brute Force inference, De Freitas, UBC</a><br>
           <a href="https://www.youtube.com/watch?v=_haafsCKsmY&t=2578s"target="_blank">Variable elimination 2, Abeel, Berkeley </a><br>

      </td>


  </TR>

  <tr style="background-color:#F5F5F5">

    <td style = "text-align:center"> 5-7  </td>
    <td> Nov. 15/22/29 2021 </td>
    <td> MAP, MPE, complexity results, moralization, running intersection property, junction tree, ... </td>
    <td> <a href="./slides/04_tud_PGM04_WiSe202122_BN3.pdf" target="_blank">.pdf</a></td>
    <td> <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week5.mp4" target="_blank">.mp4</a><br>
      <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week6.mp4" target="_blank">.mp4</a><br>
        <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week7.mp4" target="_blank">.mp4</a>
    </td>


    <td> <a href="https://www.youtube.com/watch?v=zGGGGlO8VFc"target="_blank">BN inference, Andreas & Foote, Berkeley </a><br>
         <a href="https://www.youtube.com/watch?v=7CU5uo2XwIc"target="_blank">Computational Complexity of BNs, Kwisthout & de Campos, Radbound & Belfast </a><br>
         <a href="https://www.youtube.com/watch?v=TddbmU9dHgA" target="_blank">Exact inference via junction tree, Bilmes, UW</a><br>
         <a href="https://www.youtube.com/watch?v=YJth2C5WIzU" target="_blank">Junction Tree / Conditioning, Darwiche, UCLA</a><br>

    </td>


</TR>

<tr>

  <td style = "text-align:center"> 7&8  </td>
  <td> Dec. 5/13, 2021 <br> Jan. 10 2022 </td>
  <td> Parameter Estimation, MLE, Expectation Maximization (EM), Gradient, ... </td>
  <td> <a href="./slides/05_tud_PGM05_WiSe202122_BN4.pdf" target="_blank">.pdf</a></td>
  <td> <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week7.mp4" target="_blank">.mp4</a><br>
    <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week8.mp4" target="_blank">.mp4</a><br>
    <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week9.mp4" target="_blank">.mp4</a>
  </td>
  <td> <a href="https://www.youtube.com/watch?v=NDoHheP2ww4&list=PLlDG_zCuBub6ywAIrM1DfJp8xaeVjyvwx&index=21"target="_blank">Maximum Likelihood Approach, Darwiche, UCLA </a><br>
       <a href="https://www.youtube.com/watch?v=NDoHheP2ww4&list=PLlDG_zCuBub6ywAIrM1DfJp8xaeVjyvwx&index=22"target="_blank">EM and Gradient, Darwiche, UCLA </a><br>
       <a href="https://www.youtube.com/watch?v=13wkyu5c-s4" target="_blank">Maximum Likelihood Estimation, Mausam, IIT Dehli</a><br>
       <a href="https://www.youtube.com/watch?v=JZAESnbtKS4" target="_blank">Maximum Likelihood, Gogate, UT Dallas</a><br>


  </td>


</TR>

<tr style="background-color:#F5F5F5">

  <td style = "text-align:center"> 9&10  </td>
  <td> Jan. 17&24, 2022 </td>
  <td> Bayesian Parameter Estimation, Structure Learning, Local Search, Structual EM, ... </td>
  <td> <a href="./slides/06_tud_PGM06_WiSe202122_BN5.pdf" target="_blank">.pdf</a></td>
  <td> <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week9.mp4" target="_blank">.mp4</a><br>
    <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week10.mp4" target="_blank">.mp4</a>
  </td>

  <td> <a href="https://www.youtube.com/watch?v=2kF0H262CLQ"target="_blank">Parameter Learning in BNs: Bayesian Approach, Gogate, UT Dallas </a><br>
    <a href="https://www.youtube.com/watch?v=8N0HsrBY7WI"target="_blank">Structure Learning Algs for BNs, Gogate, UT Dallas </a><br>
       <a href="https://www.youtube.com/watch?v=RV2lInyq_bI"target="_blank">Learning Network Structure, Darwiche, UCLA </a><br>
       <a href="https://www.youtube.com/watch?v=3-qjNObPEO4" target="_blank">Structure Learning and EM, Mausam, IIT Dehli</a><br>
       <a href="https://www.youtube.com/watch?v=IkyffdZrNjo" target="_blank">Learning in Bayesian Networks, Mausam, Berkeley</a><br>

  </td>


</TR>


<tr>

  <td style = "text-align:center"> 10&11  </td>
  <td> Jan. 24/31 2022 </td>
  <td> (Loopy) Belief Propagation, Sampling, Rejection Sampling, GIBBS Sampling, Likelihood Weighting, ... </td>
  <td> <a href="./slides/07_tud_PGM07_WiSe202122_BN6.pdf" target="_blank">.pdf</a></td>
  <td>     <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week10.mp4" target="_blank">.mp4</a><br>
            <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week11.mp4" target="_blank">.mp4</a>
  </td>
  <td> <a href="https://www.youtube.com/watch?v=r6zT6boHQbM"target="_blank">Loopy Belief Propagation, Darwiche, UCLA </a><br>
    <a href="https://youtu.be/meBWAboEWQk"target="_blank">Belief Propagation, Huang, Verginia Tech </a><br>
       <a href="https://www.youtube.com/watch?v=yWxjcmjkGu8"target="_blank">Loopy Belief Propagation, Batmanghelich, CMU </a><br>
       <a href="https://www.youtube.com/watch?v=ogYaTTRguIw" target="_blank">Sampling from BNs, Abbeel, Berkeley</a><br>
       <a href=" https://www.youtube.com/watch?v=cpP66Ga44ng" target="_blank">Likelihood Sampling, Mausam, IIT Dehli</a><br>

  </td>


</TR>


<tr style="background-color:#F5F5F5">

  <td style = "text-align:center"> 11  </td>
  <td> Feb. 7, 2022 </td>
  <td> Hidden Markov Models, Recursive Filters, Kalman Filter, Dynamic Bayesian Networks, ... </td>
  <td> <a href="./slides/08_tud_PGM08_WiSe202122_BN7.pdf" target="_blank">.pdf</a></td>
  <td>     <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week11.mp4" target="_blank">.mp4</a>
  </td>
  <td> <a href="https://youtu.be/lecy8kEjC3Q"target="_blank">Dynamic Bayesian Networks, Koller, Stanford </a><br>
    <a href="https://youtu.be/5araDjcBHMQ"target="_blank">Hidden Markov Models, Bobick, Udacity </a><br>
       <a href="https://youtu.be/0u80UvCAKVo"target="_blank">Hidden Markov Models, Andreas, Berkeley </a><br>
       <a href="https://youtu.be/0lKHFJpaZvE" target="_blank">Recursive Bayes Filter, Stachniss, U Bonn</a><br>
       <a href="https://youtu.be/E-6paM_Iwfc" target="_blank">Kalman Filter and EKF, Stachniss, U Bonn</a><br>




  </td>

  <tr >

    <td style = "text-align:center"> 12  </td>
    <td> Feb. 14, 2022 </td>
    <td> Sum-Product Networks, Q&A ... </td>
    <td> <a href="./slides/09_tud_PGM09_WiSe202122_probCircuits.pdf" target="_blank">.pdf</a></td>
    <td>     <a href="https://moodleload.hrz.tu-darmstadt.de/FB20_DaMi/PGM_WiSe2020/Week12.mp4" target="_blank">.mp4</a>
    </td>

    <td> <a href="https://youtu.be/2RAG5-L9R70"target="_blank">Probabilistic Circuits, Vergari, Choi, Peharz, Van den Broeck, ECMLPKDD 2020 Tutorial </a><br>
      <a href="https://www.youtube.com/watch?v=eF0APeEIJNw"target="_blank">Sum-Product Networks, Poupart, Waterloo </a><br>
         <a href="https://youtu.be/dCoCTVcGsEA"target="_blank">Arithmetic Circtuis and SPNs, Darwiche, UCLA </a><br>
         <a href="https://youtu.be/uxBQS8-ZmBA" target="_blank">Random SPNs, Peharz, UAI 2019</a><br>
         <a href="https://youtu.be/QegQUBz99o4" target="_blank">Sum-Product Networks, Domingos, UW</a><br>




    </td>


</TR>

</table>

</p>

</div>

<br>



<hr class="soft">

<div class="container" id="logistics">

<h3>Assignments and Exercises</h3>

<p>
Aside from the “5-questions” homework, there are also four written
assignments involving both theory and programming. Handing in those assignments regularly will earn
you a bonus for the final exam. Pleses visit Moodle for further information, and for submitting them.
</p>

</div>

<br>

<hr class="soft">
<br>

<div class="container" id="infos">

<h3>Further Material and Links</h3>

<p>

<ul>


  <li> Probabilistic Graphical Models: Principles and Techniques by Daphen Koller and Nir Friedman.</li>

  <li> Modeling and Reasoning with Bayesian networks by Adnan Darwiche.</li>

<li> Pattern Recognition and Machine Learning by Chris Bishop.</li>

<li> Machine Learning: a Probabilistic Perspective by Kevin P. Murphy.</li>

<li> Information Theory, Inference, and Learning Algorithms by David J. C. Mackay. Available online.</li>

<li> Bayesian Reasoning and Machine Learning by David Barber. Available online.</li>

<li> Graphical models, exponential families, and variational inference by Martin J. Wainwright and Michael I. Jordan. Available online</li>


</p>

</div>



<hr class="soft" id="legal">


</main>
<footer>


<div class="container" id="sitefooter">


<a href="https://www.informatik.tu-darmstadt.de/impressum.en.jsp">Legal info / Impressum</a> <br><br>

Technische Universitaet Darmstadt <br>
Fachbereich Informatik <br>
Hochschulstr. 1 <br>
64289 Darmstadt<br>
Germany<br><br>

</div>

</footer>


<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.1/js/bootstrap.bundle.min.js"></script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/datatables/1.10.19/js/jquery.dataTables.min.js"></script>

<script type="text/javascript" src="./../../build/bib-list.js"></script>


<script type="text/javascript">
    $(document).ready(function () {
  $.get('https://ml-research.github.io/references.bib', function (data) {
  //  $.get('file:///Users/kersting/Documents/GitHub/ml-research.github.io/references.bib', function (data) {

            function containsName(bib) {
                return bib.toLowerCase().includes("kersting")
            }

            function replaceImagePath(bib) {
                return bib.replace("./images/", "./../../images/");
            }

            function replacePaperPath(bib) {
                return bib.replace("./papers/", "./../../papers/");
            }

            bibtex = data.split(/(?=@\w+)/u);
            my_bibtex = bibtex.filter(containsName).map(replacePaperPath);
            my_bibtex = my_bibtex.map(replaceImagePath);

            $("#bibtex").html(my_bibtex.join());
            bibtexify("#bibtex", "pubTable");
        });


    });
</script>



<!--<script type="text/javascript">
        $(document).ready(function() {
          bibtexify("#bibtex", "pubTable");
        });
</script>-->



</body>
</html>
